---
title: "GenSA and BayesianTools comparison"
author: "Pepa Aran"
date: "2023-06-14"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Calibration comparison

In this analysis report, we will check the agreement of the two implemented calibration routines, for a set of relevant model parameters used in the "Sensitivity Analysis" vignette.

### Calibration with BayesianTools

We start by running the Bayesian calibration in the "Sensitivity Analysis" vignette, this time without burnin to see the evolution of the chains. 

```{r}
# Calibrates the kphio-related parameters
set.seed(2023)

# Define calibration settings
settings_calib <- list(
  method = "BayesianTools",
  metric = rsofun::cost_likelihood_pmodel,
  control = list(
    sampler = "DEzs",
    settings = list(
      burnin = 3000,
      iterations = 9000,
      startValue = 3       # number of chains to be sampled
    )),
  par = list(
    kphio = list(lower = 0.03, upper = 0.15, init = 0.05),
    kphio_par_a = list(lower = -0.004, upper = -0.001, init = -0.0025),
    kphio_par_b = list(lower = 10, upper = 30, init =25),
    err_gpp = list(lower = 0.1, upper = 3, init = 0.8)
  )
)

# calibrate parameters kphio and err_gpp 
par_calib_bt <- calib_sofun(
  drivers = p_model_drivers,
  obs = p_model_validation,
  settings = settings_calib,
  par_fixed = list(
    soilm_thetastar    = 0.6*240,
    soilm_betao        = 0.2,
    beta_unitcostratio = 146.0,
    rd_to_vcmax        = 0.014,
    tau_acclim         = 30.0,
    kc_jmax            = 0.41),
  targets = "gpp"
)
```

```{r eval = TRUE, echo = FALSE}
load("vignettes/files/par_calib.rda")
par_calib_bt <- par_calib
```

Let's observe the output:
```{r fig.width = 7, fig.height = 10}
# Optimal parameter values
par_calib_bt$par
# Trace plots of MCMC samples
plot(par_calib_bt$mod)
```

### Calibration with GensA

Next we run the calibration with GenSA using the RMSE of predicted vs observed GPP as the optimization objective.
```{r}
# Calibrates the kphio-related parameters
set.seed(2023)

# Define calibration settings
settings_calib <- list(
  method = "GenSA",
  metric = rsofun::cost_rmse_pmodel,
  control = list(
    maxit = 100
    ),
  par = list(
    kphio = list(lower = 0.03, upper = 0.15, init = 0.05),
    kphio_par_a = list(lower = -0.004, upper = -0.001, init = -0.0025),
    kphio_par_b = list(lower = 10, upper = 30, init =25)
  )
)

# calibrate parameters kphio and err_gpp 
par_calib_gensa <- calib_sofun(
  drivers = p_model_drivers,
  obs = p_model_validation,
  settings = settings_calib,
  par_fixed = list(
    soilm_thetastar    = 0.6*240,
    soilm_betao        = 0.2,
    beta_unitcostratio = 146.0,
    rd_to_vcmax        = 0.014,
    tau_acclim         = 30.0,
    kc_jmax            = 0.41),
  targets = "gpp"
)
```

Let's compare the calibrated values from both algorithms:
```{r}
par_calib_gensa$par

par_calib_bt$par
```

As curiosity, when does GenSA reach the minimum RMSE? 3rd try! That's impressive or suspicious...
```{r}
plot(par_calib_gensa$mod$trace.mat[, 4], type = 'l',
     ylab = "RMSE", xlab = "# cost evaluations")
```

## Conclusion

Optimal parameter values are similar, so the sanity check passes.
